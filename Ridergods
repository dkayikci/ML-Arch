"""Automated Style Detection2+noerror.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10yZ6it25NgtEcuwQOiesXLQtwbFS_hgS
"""

# Rock Relief Clustering with Enhanced Style Detection
# Path: ridergods2

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import cv2
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.manifold import TSNE
from sklearn.neighbors import NearestNeighbors
from scipy.spatial.distance import pdist, squareform
from scipy.cluster.hierarchy import dendrogram, linkage
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from google.colab import drive
import seaborn as sns
from scipy.stats import mode
from skimage.feature import hog, local_binary_pattern
from skimage import feature, transform
import warnings
warnings.filterwarnings('ignore')

# Set global random seed for reproducibility
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

# Configuration
KNOWN_SIMILAR_INDICES = [
    [0, 11, 17, 18, 19],  # Replace with actual indices of the 5 images you know are the same style
]

# Mount Google Drive to access your data
drive.mount('/content/drive')

# Set the path directly to your images folder as requested
dataset_path = '/content/drive/MyDrive/ridergods2/images'

# Create output directory
output_path = '/content/drive/MyDrive/ridergods2/results'
os.makedirs(output_path, exist_ok=True)

# Print directory structure for debugging
print(f"Dataset path: {dataset_path}")
print(f"Output path: {output_path}")

# Check if directories exist and list contents
def check_directory(path):
    if os.path.exists(path):
        print(f"Directory '{path}' exists.")
        files = os.listdir(path)
        print(f"Found {len(files)} files/folders.")
        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        print(f"Found {len(image_files)} image files.")
        if len(image_files) > 0:
            print(f"Sample image files: {image_files[:5]}")
    else:
        print(f"Directory '{path}' does not exist!")

check_directory(dataset_path)

# Helper Functions
def load_and_preprocess_images(image_folder, target_size=(224, 224), convert_to_grayscale=True):
    """
    Load images from folder, resize them, and optionally convert to grayscale
    """
    images = []
    filenames = []

    # Check if directory exists
    if not os.path.isdir(image_folder):
        print(f"Error: {image_folder} is not a valid directory!")
        return images, filenames

    # List all image files in the directory
    file_list = []
    for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:
        file_list.extend([f for f in os.listdir(image_folder) if f.endswith(ext)])

    file_list = sorted(file_list)
    print(f"Found {len(file_list)} image files in {image_folder}")

    for filename in file_list:
        img_path = os.path.join(image_folder, filename)

        # Check if it's a file, not a directory
        if not os.path.isfile(img_path):
            print(f"Skipping {img_path}, not a file")
            continue

        # Read image
        try:
            img = cv2.imread(img_path)

            if img is None:
                print(f"Warning: Failed to read {img_path}")
                continue

            # Resize image
            img = cv2.resize(img, target_size)

            # Convert to grayscale if specified
            if convert_to_grayscale:
                if len(img.shape) == 3 and img.shape[2] == 3:
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # Enhanced preprocessing for style analysis
            # Apply bilateral filter to smooth while preserving edges
            img = cv2.bilateralFilter(img, 9, 75, 75)

            # Apply CLAHE for better contrast
            if len(img.shape) == 2:  # Only for grayscale
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                img = clahe.apply(img)

            images.append(img)
            filenames.append(filename)
        except Exception as e:
            print(f"Error processing {img_path}: {str(e)}")

    return images, filenames

def extract_features_for_style_analysis(images):
    """
    Extract features optimized for style analysis
    - Emphasizes shape and structural elements
    - Reduces emphasis on surface details
    """
    if len(images) == 0:
        print("No images to extract features from!")
        return np.array([])

    all_features = []

    for i, img in enumerate(images):
        try:
            features = []

            # 1. Shape Analysis using Hu Moments (important for style)
            moments = cv2.moments(img)
            hu_moments = cv2.HuMoments(moments).flatten()
            # Apply log transform to reduce scale difference
            hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)
            # Add twice to increase weight for shape features
            features.extend(hu_moments)
            features.extend(hu_moments)

            # 2. HOG Feature Descriptor with larger cell size (captures structural elements while ignoring details)
            hog_features = hog(img, orientations=12, pixels_per_cell=(16, 16),
                          cells_per_block=(2, 2), visualize=False, feature_vector=True)
            features.extend(hog_features)

            # 3. Texture Analysis using LBP (with larger radius to focus on broader patterns)
            radius = 4  # Increased radius
            n_points = 8 * radius
            lbp = local_binary_pattern(img, n_points, radius, method='uniform')
            lbp_histogram, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))
            lbp_histogram = lbp_histogram.astype("float")
            lbp_histogram /= (lbp_histogram.sum() + 1e-7)  # Normalize
            features.extend(lbp_histogram)

            # 4. Edge Detection (reduced importance for style analysis)
            edges = cv2.Canny(img, 100, 200)
            edge_histogram = cv2.calcHist([edges], [0], None, [32], [0, 256]).flatten()  # Reduced bins
            edge_histogram = edge_histogram.astype("float")
            edge_histogram /= (np.sum(edge_histogram) + 1e-7)  # Normalize
            edge_histogram *= 0.5  # Reduce weight of edge features
            features.extend(edge_histogram)

            all_features.append(features)

            # Print progress
            if (i+1) % 20 == 0:
                print(f"Extracted features from {i+1}/{len(images)} images")

        except Exception as e:
            print(f"Error extracting features from image {i}: {str(e)}")
            # If we already have some features, use the same length
            if all_features:
                all_features.append(np.zeros_like(all_features[0]))
            else:
                # Skip this image if it's the first one with an error
                continue

    if len(all_features) == 0:
        print("Failed to extract features from any images!")
        return np.array([])

    return np.array(all_features)

def determine_optimal_clusters_kmeans(features, max_clusters=10):
    """
    Determine the optimal number of clusters (styles) using K-means and multiple validation metrics
    """
    if features.shape[0] == 0:
        print("No features to determine clusters!")
        return 2, [], [], []

    # 1. Prepare metrics storage
    silhouette_scores = []
    davies_bouldin_scores = []
    calinski_harabasz_scores = []

    # 2. Calculate cluster validation metrics for different numbers of clusters
    for n_clusters in range(2, min(max_clusters + 1, features.shape[0])):
        try:
            # Use K-means clustering
            kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_SEED, n_init=10)
            labels = kmeans.fit_predict(features)

            # Calculate silhouette score
            sil_score = silhouette_score(features, labels)
            silhouette_scores.append(sil_score)

            # Calculate Davies-Bouldin score (lower is better)
            db_score = davies_bouldin_score(features, labels)
            davies_bouldin_scores.append(db_score)

            # Calculate Calinski-Harabasz score (higher is better)
            ch_score = calinski_harabasz_score(features, labels)
            calinski_harabasz_scores.append(ch_score)

            print(f"Clusters: {n_clusters}, Silhouette: {sil_score:.4f}, Davies-Bouldin: {db_score:.4f}, Calinski-Harabasz: {ch_score:.2f}")
        except Exception as e:
            print(f"Error calculating metrics for {n_clusters} clusters: {str(e)}")
            silhouette_scores.append(-1)
            davies_bouldin_scores.append(float('inf'))
            calinski_harabasz_scores.append(-1)

    # 3. Plot the validation metrics
    plt.figure(figsize=(15, 5))

    # Silhouette score (higher is better)
    plt.subplot(1, 3, 1)
    plt.plot(range(2, 2 + len(silhouette_scores)), silhouette_scores, 'o-', linewidth=2, markersize=8)
    plt.xlabel('Number of Clusters (Styles)')
    plt.ylabel('Silhouette Score')
    plt.title('Silhouette Score (Higher is Better)')
    plt.grid(True)

    # Davies-Bouldin score (lower is better)
    plt.subplot(1, 3, 2)
    plt.plot(range(2, 2 + len(davies_bouldin_scores)), davies_bouldin_scores, 'o-', linewidth=2, markersize=8)
    plt.xlabel('Number of Clusters (Styles)')
    plt.ylabel('Davies-Bouldin Score')
    plt.title('Davies-Bouldin Score (Lower is Better)')
    plt.grid(True)

    # Calinski-Harabasz score (higher is better)
    plt.subplot(1, 3, 3)
    plt.plot(range(2, 2 + len(calinski_harabasz_scores)), calinski_harabasz_scores, 'o-', linewidth=2, markersize=8)
    plt.xlabel('Number of Clusters (Styles)')
    plt.ylabel('Calinski-Harabasz Score')
    plt.title('Calinski-Harabasz Score (Higher is Better)')
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(output_path, 'cluster_validation_metrics.png'))

    # 4. Determine optimal number of clusters using the metrics
    if len(silhouette_scores) == 0:
        print("Failed to calculate metrics, defaulting to 2 clusters")
        return 2, [], [], []

    # Normalize scores for comparison (handle invalid scores)
    valid_sil = np.array([s if s >= 0 else 0 for s in silhouette_scores])
    max_sil = np.max(valid_sil) if np.max(valid_sil) > 0 else 1
    norm_silhouette = valid_sil / max_sil

    valid_db = np.array([s if s < float('inf') else np.max([x for x in davies_bouldin_scores if x < float('inf')])
                         for s in davies_bouldin_scores])
    max_db = np.max(valid_db) if np.max(valid_db) > 0 else 1
    norm_davies_bouldin = 1 - (valid_db / max_db)

    valid_ch = np.array([s if s >= 0 else 0 for s in calinski_harabasz_scores])
    max_ch = np.max(valid_ch) if np.max(valid_ch) > 0 else 1
    norm_calinski_harabasz = valid_ch / max_ch

    # Combine scores (weighted average)
    combined_scores = (0.5 * norm_silhouette + 0.25 * norm_davies_bouldin + 0.25 * norm_calinski_harabasz)

    # Find the best number of clusters
    if len(combined_scores) > 0:
        optimal_k = np.argmax(combined_scores) + 2  # +2 because we start from 2 clusters
    else:
        optimal_k = 2  # Default if no valid scores

    # 5. Perform hierarchical clustering for visualization
    plt.figure(figsize=(12, 8))

    try:
        # Perform hierarchical clustering
        Z = linkage(features, method='ward')

        # Plot dendrogram
        dendrogram(Z, leaf_rotation=90., leaf_font_size=8., color_threshold=0.7*np.max(Z[:,2]))
        plt.title('Hierarchical Clustering Dendrogram', fontsize=16)
        plt.xlabel('Image Index', fontsize=12)
        plt.ylabel('Distance', fontsize=12)

        # Add a horizontal line at the cut for optimal_k clusters
        if len(Z) >= optimal_k - 1:
            plt.axhline(y=Z[-(optimal_k-1), 2], color='r', linestyle='--',
                        label=f'Cut for {optimal_k} clusters')
            plt.legend()
    except Exception as e:
        print(f"Error generating dendrogram: {str(e)}")

    plt.tight_layout()
    plt.savefig(os.path.join(output_path, 'hierarchical_clustering_dendrogram.png'))

    print(f"\nOptimal number of clusters (styles): {optimal_k}")
    if len(silhouette_scores) >= optimal_k - 2:
        print(f"Silhouette score for {optimal_k} clusters: {silhouette_scores[optimal_k-2]:.4f}")

    return optimal_k, silhouette_scores, davies_bouldin_scores, calinski_harabasz_scores

def perform_constrained_kmeans(features, n_clusters, known_similar_indices=None, random_state=RANDOM_SEED):
    # First run standard K-means
    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)
    initial_labels = kmeans.fit_predict(features)

    # If no constraints, return initial labels
    if not known_similar_indices or len(known_similar_indices) == 0:
        return initial_labels

    # Apply constraints - force similar images to have the same label
    final_labels = initial_labels.copy()

    for group in known_similar_indices:
        valid_indices = [idx for idx in group if idx < len(final_labels)]
        if len(valid_indices) > 1:
            group_labels = [initial_labels[idx] for idx in valid_indices]

            # Fix: More robust handling of mode calculation
            unique_labels, counts = np.unique(group_labels, return_counts=True)
            if len(unique_labels) > 0:
                most_common = unique_labels[np.argmax(counts)]

                # Assign all images in this group to the most common cluster
                for idx in valid_indices:
                    final_labels[idx] = most_common

    return final_labels

def plot_clusters_with_tsne(features, labels, title, filenames=None, save_path=None):
    """
    Plot clusters using t-SNE for better visualization of high-dimensional data
    """
    if features.shape[0] == 0:
        print("No features to plot!")
        return None

    # Apply t-SNE to reduce dimensions to 2D
    perplexity_value = min(30, features.shape[0] - 1)  # Adjust perplexity based on data size
    tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=RANDOM_SEED)
    tsne_result = tsne.fit_transform(features)

    plt.figure(figsize=(14, 12))

    # Get unique clusters
    unique_clusters = np.unique(labels)
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_clusters)))

    # Plot each cluster
    for cluster_id, color in zip(unique_clusters, colors):
        # Get indices of points in this cluster
        indices = np.where(labels == cluster_id)[0]
        if len(indices) == 0:
            continue

        cluster_points = tsne_result[indices]

        # Plot the points
        plt.scatter(cluster_points[:, 0], cluster_points[:, 1],
                   color=color, marker='o', s=100,
                   label=f'Style {cluster_id+1}',
                   alpha=0.9, edgecolors='black')

        # If filenames are provided, add annotations for images
        if filenames is not None:
            for i in indices:
                if i < len(tsne_result):
                    plt.annotate(f"{i}", (tsne_result[i, 0], tsne_result[i, 1]),
                                 fontsize=9, bbox=dict(boxstyle="round,pad=0.2", fc="white", alpha=0.7))

    plt.title(title, fontsize=18)
    plt.xlabel('t-SNE dimension 1', fontsize=14)
    plt.ylabel('t-SNE dimension 2', fontsize=14)
    plt.legend(fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)

    return plt

def visualize_cluster_representatives(images, labels, filenames, n_clusters, n_samples=3, save_path=None):
    """
    Visualize representative images from each cluster to help interpret styles
    """
    if len(images) == 0 or len(labels) == 0:
        print("No images or labels to visualize!")
        return None

    plt.figure(figsize=(n_samples*4, n_clusters*4))

    for cluster_id in range(n_clusters):
        # Get indices of images in this cluster
        cluster_indices = np.where(labels == cluster_id)[0]

        if len(cluster_indices) == 0:
            continue

        # Select representative images
        n_to_show = min(n_samples, len(cluster_indices))
        samples = cluster_indices[:n_to_show]

        # Plot each representative
        for i, idx in enumerate(samples):
            if idx < len(images):
                plt.subplot(n_clusters, n_samples, cluster_id*n_samples + i + 1)

                # Show the image
                plt.imshow(images[idx], cmap='gray')
                plt.title(f"Style {cluster_id+1}: {filenames[idx]}\nImage Index: {idx}", fontsize=10)
                plt.axis('off')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)

    return plt

# Main Execution
def main():
    # Set random seeds again for extra safety
    np.random.seed(RANDOM_SEED)
    tf.random.set_seed(RANDOM_SEED)

    print(f"Using random seed: {RANDOM_SEED} for reproducible results")
    print("Starting Kibyratis Rock Relief Clustering Analysis")

    # Step 1: Load and preprocess images
    print("Loading and preprocessing images...")
    images, filenames = load_and_preprocess_images(dataset_path)
    print(f"Loaded {len(images)} images")

    if len(images) == 0:
        print("No images were loaded. Please check the image directory path.")
        return

    # Create and save index to filename mapping
    mapping_df = pd.DataFrame({
        'Index': range(len(filenames)),
        'Filename': filenames
    })
    mapping_df.to_csv(os.path.join(output_path, 'index_to_filename.csv'), index=False)
    print("Index to filename mapping saved to 'index_to_filename.csv'")

    # Step 2: Extract features optimized for style analysis
    print("\n=== EXTRACTING STYLE FEATURES ===")
    style_features = extract_features_for_style_analysis(images)
    print(f"Feature array shape: {style_features.shape}")

    if style_features.shape[0] == 0:
        print("Failed to extract features. Exiting.")
        return

    # Step 3: Normalize features
    print("Normalizing features...")
    scaler = RobustScaler()  # Use RobustScaler to handle outliers better
    normalized_features = scaler.fit_transform(style_features)

    # Step 4: Determine optimal number of clusters (styles) using K-means
    print("\n=== DETERMINING OPTIMAL NUMBER OF STYLES ===")
    optimal_clusters, silhouette_scores, davies_bouldin_scores, calinski_harabasz_scores = determine_optimal_clusters_kmeans(
        normalized_features,
        max_clusters=min(10, len(images) // 2)  # Limit max clusters based on dataset size
    )

    # Step 5: Final clustering with optimal number of clusters and constraints
    print(f"\n=== PERFORMING FINAL CLUSTERING WITH {optimal_clusters} STYLES ===")

    try:
        # Perform constrained K-means clustering
        final_labels = perform_constrained_kmeans(
            normalized_features,
            n_clusters=optimal_clusters,
            known_similar_indices=KNOWN_SIMILAR_INDICES,
            random_state=RANDOM_SEED
        )

        # Step 6: Visualize results
        print("\n=== VISUALIZING RESULTS ===")

        # Plot clusters using t-SNE
        tsne_plot = plot_clusters_with_tsne(
            normalized_features,
            final_labels,
            f"Rock Relief Clustering: {optimal_clusters} Distinct Styles Detected",
            filenames,
            save_path=os.path.join(output_path, 'style_clusters_tsne.png')
        )

        # Visualize representative images from each cluster
        rep_plot = visualize_cluster_representatives(
            images,
            final_labels,
            filenames,
            optimal_clusters,
            n_samples=min(5, len(images) // optimal_clusters),
            save_path=os.path.join(output_path, 'style_representatives.png')
        )

        # Step 7: Create detailed report
        print("\n=== GENERATING STYLE ANALYSIS REPORT ===")

        # Count images in each style cluster
        style_counts = {}
        for cluster_id in range(optimal_clusters):
            count = np.sum(final_labels == cluster_id)
            style_counts[cluster_id] = count
            print(f"Style {cluster_id+1}: {count} images ({count/len(images)*100:.1f}%)")

        # Verify consistency with known similar images
        consistency_verified = True
        for group in KNOWN_SIMILAR_INDICES:
            valid_indices = [idx for idx in group if idx < len(final_labels)]
            if len(valid_indices) > 1:
                labels_in_group = [final_labels[idx] for idx in valid_indices]
                if len(set(labels_in_group)) > 1:
                    consistency_verified = False
                    print(f"Warning: Known similar images {valid_indices} were assigned to different styles: {labels_in_group}")
                else:
                    print(f"Verified: Known similar images {valid_indices} were correctly assigned to the same style: {labels_in_group[0]+1}")

        # Create comprehensive output table
        output_df = pd.DataFrame({
            'Index': range(len(images)),
            'Filename': filenames,
            'Style_Cluster': [f"Style {label+1}" for label in final_labels]
        })

        # Add notes about known similar images
        known_similar_flat = [item for sublist in KNOWN_SIMILAR_INDICES for item in sublist]
        output_df['Known_Similar'] = output_df['Index'].apply(lambda x: 'Yes' if x in known_similar_flat else 'No')

        # Save detailed output
        output_df.to_csv(os.path.join(output_path, 'style_analysis_results.csv'), index=False)
        print(f"Style analysis results saved to: {os.path.join(output_path, 'style_analysis_results.csv')}")

        # Final summary
        print("\n=== STYLE ANALYSIS SUMMARY ===")
        print(f"Total rock reliefs analyzed: {len(images)}")
        print(f"Number of distinct styles detected: {optimal_clusters}")
        for cluster_id in range(optimal_clusters):
            count = style_counts[cluster_id]
            print(f"Style {cluster_id+1}: {count} reliefs ({count/len(images)*100:.1f}%)")

        print(f"\nKnown similar images correctly grouped: {'Yes' if consistency_verified else 'No'}")
        if len(silhouette_scores) >= optimal_clusters-2:
            print(f"Silhouette score: {silhouette_scores[optimal_clusters-2]:.4f}")

        print("\nAnalysis complete. Results have been saved to your Google Drive.")

    except Exception as e:
        print(f"Error during clustering and visualization: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
